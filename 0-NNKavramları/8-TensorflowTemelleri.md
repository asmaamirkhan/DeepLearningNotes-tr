# ğŸƒâ€â™€ï¸ Tensorflow'ya HÄ±zlÄ± GiriÅŸ

## ğŸš© Tensorflow'daki programlarÄ±n ana akÄ±ÅŸÄ±
1. Daha _execute_ edilmemiÅŸ _tensor_'larÄ± oluÅŸtur
2. _Tensor_'larÄ±n arasÄ±ndaki iÅŸlemeleri yaz
3. _Tensor_'larÄ± baÅŸlat _(initialize)_
4. Bir _Session_ oluÅŸtur
5. _Session_'Ä± Ã§alÄ±ÅŸtÄ±r. Bu, yukarÄ±da yazdÄ±ÄŸÄ±n iÅŸlemleri yÃ¼rÃ¼tecektir.

> Ã–zetle, deÄŸiÅŸkenleri baÅŸlatm, bir _Session_ oluÅŸtur ve _Session_'Ä±n iÃ§indeki iÅŸlemleri Ã§alÄ±ÅŸtÄ±r ğŸ‘©â€ğŸ«

## ğŸ‘©â€ğŸ’» Kod Ã–rneÄŸi
AÅŸaÄŸÄ±daki formÃ¼lÃ¼ hesaplamak iÃ§in:

$$loss=L(\hat{y},y)=(\hat{y}^{(i)}-y^{(i)})^2$$

```python
# TensÃ¶rleri oluÅŸturma ve arasÄ±ndaki iÅŸlemi yapma 
y_hat = tf.constant(36, name='y_hat')
y = tf.constant(39, name='y')
loss = tf.Variable((y - y_hat)**2, name='loss')

# TensÃ¶rleri baÅŸlatma
init = tf.global_variables_initializer()

# Session oluÅŸturma
with tf.Session() as session: 
    # Ä°ÅŸlemeleri Ã§alÄ±ÅŸtÄ±rma
    session.run(init) 

    # SonuÃ§larÄ± yazdÄ±rma
    print(session.run(loss)) 
```

> _Loss_ iÃ§in bir deÄŸiÅŸken oluÅŸturduÄŸumuzda, _loss_'u basitÃ§e diÄŸer miktarlarÄ±n bir fonksiyonu olarak tanÄ±mladÄ±k, ancak deÄŸerini deÄŸerlendirmedik. Bunu deÄŸerlendirmek iÃ§in _initializer_'Ä± kullanÄ±rÄ±z.

## â— DeÄŸiÅŸken BaÅŸlatma _(initalization)_ HakkÄ±nda Not

AÅŸaÄŸÄ±daki kod iÃ§in

```python
a = tf.constant(2)
b = tf.constant(10)
c = tf.multiply(a,b)
print(c)
```

ğŸ¤¸â€â™€ï¸ Ã‡Ä±ktÄ±:

```
Tensor("Mul:0", shape=(), dtype=int32)
```

BeklendiÄŸi gibi, 20 gÃ¶rmeyeceÄŸiz ğŸ¤“! Sonucun _shape attribute_'u olmayan ve "int32" tÃ¼rÃ¼nde bir tensÃ¶r olduÄŸunu sÃ¶yleyen bir tensÃ¶rÃ¼mÃ¼z var. Tek yaptÄ±ÄŸÄ±mÄ±z **'computation graph'** koymaktÄ±, ancak henÃ¼z bu hesaplamayÄ± Ã§alÄ±ÅŸtÄ±rmadÄ±k.

## ğŸ“¦ TF'deki Placeholders 
- Yer tutucu _placeholder_, deÄŸerini **ancak daha sonra** belirleyebileceÄŸiniz bir nesnedir. Bir yer tutucunun deÄŸerlerini belirtmek iÃ§in, bir `feed dictionary` kullanarak deÄŸerleri iletebiliriz.
- AÅŸaÄŸÄ±da, x iÃ§in bir yer tutucu oluÅŸturuldu. Bu, Session'Ä± Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±zda daha sonra bir sayÄ± girmemizi saÄŸlar.

```python
x = tf.placeholder(tf.int64, name = 'x')
print(sess.run(2 * x, feed_dict = {x: 3}))
sess.close()
```

## ğŸ€ Daha Fazla Ã–rnek
_Sigmoid_ Fonksiyonun deÄŸerini TF ile hesaplamak

```python
def sigmoid(z):
    """
    z deÄŸeri iÃ§in sigmoid fonksiyonunu hesaplar
    
    ArgÃ¼manlar:
    z -- giriÅŸ deÄŸeri, skaler veya vectÃ¶r
    
    DÃ¶nÃ¼ÅŸ deÄŸeri: 
    results -- z'nin sigmoid deÄŸeri 
    """
    
    # x iÃ§in yertutucu tanÄ±mlama. adÄ± da 'x'.
    x =  tf.placeholder(tf.float32, name = 'x')

    # sigmoid(x)'i hesaplama
    sigmoid = tf.sigmoid(x)

    # session oluÅŸturma, ve Ã§alÄ±ÅŸtÄ±rma.
    with tf.Session() as sess:
        # session'Ä± Ã§alÄ±ÅŸtÄ±rma ve sonuÃ§larÄ± output'a (result'a) atama
        result = sess.run(sigmoid, feed_dict = {x: z})
        
    return result
```

_Cost_ Fonksiyonun deÄŸerini TF ile hesaplamak

```python
def cost(logits, labels):
    """
Â Â Â Â sigmoid cross entropy ile cost fonksiyonunun deÄŸerini hesaplar
Â Â Â Â 
Â Â Â Â ArgÃ¼manlar:
Â Â Â Â logits -- z'yi iÃ§eren bir vektÃ¶r, Son lineer Ã¼nitenin Ã§Ä±ktÄ±sÄ± (son sigmoid aktivasyonundan Ã¶nce)
Â Â Â Â labels -- y - etiket vektÃ¶rÃ¼ (1 veya 0) 
    
Â Â Â Â DÃ¶nÃ¼ÅŸ DeÄŸeri:
Â Â Â Â cost -- Cost fonksiyonunun session'Ä±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±r
    """
    
    # "logits" (z) ve "labels" (y) iÃ§in yer tutucu oluÅŸturma 
    z = tf.placeholder(tf.float32, name = 'z')
    y = tf.placeholder(tf.float32, name = 'y')
    
    # Loss fonksiyonunu kullanma
    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits = z,  labels = y)
    
    # Session oluÅŸturma
    sess = tf.Session()
    
    # Session'Ä± Ã§alÄ±ÅŸtÄ±rma 
    cost = sess.run(cost, feed_dict = {z: logits, y: labels})
    
    # Session'Ä± kapatma
    sess.close()
        
    return cost
```

## ğŸŒ YazÄ±nÄ±n AslÄ±
- [Burada ğŸ¾](https://dl.asmaamir.com/0-nnconcepts/8-tensorflowbasics)