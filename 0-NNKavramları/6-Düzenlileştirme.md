# ğŸ‘©â€ğŸ”§ NN DÃ¼zenlileÅŸtirme (Regularization)
KÄ±saca: AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nleyen -ve varyansÄ±- azaltan bir tekniktir

## ğŸ™„ Problem
AÅŸÄ±rÄ± Ã¶ÄŸrenme durumunda, modelimiz eÄŸitim verilerindeki ayrÄ±ntÄ±larÄ± ve daha Ã¶nce gÃ¶rÃ¼lmeyen veriler (test seti) Ã¼zerinde dÃ¼ÅŸÃ¼k performansa neden olan gÃ¼rÃ¼ltÃ¼yÃ¼ Ã§ok iyi Ã¶ÄŸrenmeye Ã§alÄ±ÅŸÄ±r.

AÅŸaÄŸÄ±daki grafik daha iyi aÃ§Ä±klar:

<img src="../res/Overfitting.png" width="300"  />

## ğŸ‘©â€ğŸ« DÃ¼zenlileÅŸtirme Daha Ä°yi TanÄ±mÄ±
Modelin daha iyi genelleÅŸmesi iÃ§in Ã¶ÄŸrenme algoritmasÄ±nda ufak deÄŸiÅŸiklikler yapan bir tekniktir. Bu da modelin gÃ¶rÃ¼nmeyen veriler Ã¼zerindeki performansÄ±nÄ± artÄ±rmaktadÄ±r.

## ğŸ”¨ DÃ¼zenlileÅŸtirme Teknikleri

### ğŸ”© L2 DÃ¼zenlileÅŸtirmesi (Weight Decay)
En yaygÄ±n dÃ¼zenlileÅŸtirme tÃ¼rÃ¼dÃ¼r, aÅŸaÄŸÄ±daki formÃ¼le gÃ¶re uygulanÄ±r 

$$J=Loss+\frac{\lambda}{2m}-\sum ||w||^{2}$$

Burada, lambda dÃ¼zenlileÅŸtirme parametresidir. Daha iyi sonuÃ§lar iÃ§in deÄŸeri optimize edilmiÅŸ olan **hiper-parametredir**. L2 dÃ¼zenlileÅŸtirmesi, aÄŸÄ±rlÄ±klarÄ± sÄ±fÄ±ra indirgemeye zorladÄ±ÄŸÄ± iÃ§in aÄŸÄ±rlÄ±k azalmasÄ± _(Weight decay)_ olarak da bilinir (ancak tam olarak sÄ±fÄ±r deÄŸildir)

### ğŸ”© SÃ¶nÃ¼mleme (Dropout)
BazÄ± sinirleri **rastgele** belirli bir oranda elimine ederek baÅŸka bir dÃ¼zenlileÅŸtirme yÃ¶ntemidir.

> BasitÃ§e: Her p olasÄ±lÄ±ÄŸÄ±na sahip dÃ¼ÄŸÃ¼mÃ¼ iÃ§in, geri yayÄ±lma sÄ±rasÄ±nda giriÅŸ veya Ã§Ä±kÄ±ÅŸ aÄŸÄ±rlÄ±klarÄ±nÄ± gÃ¼ncellemiyoruz (Yani onu dÃ¼ÅŸÃ¼rÃ¼yoruz ğŸ˜…)

Daha iyi gÃ¶rselleÅŸtirme:
<p float="left">
    <img src="../res/NNWithoutDropout.JPG" width="200"  />
    <img src="../res/NNWithDropout.JPG" width="200"  />
</p>

> Eleme iÅŸleminden Ã¶nce ve sonra bir NN

Genellikle bilgisayarlÄ± gÃ¶rÃ¼ÅŸte kullanÄ±lÄ±r, ancak olumsuz yÃ¶nÃ¼ maliyet fonksiyonunun _J_ artÄ±k iyi tanÄ±mlanmadÄ±ÄŸÄ±dÄ±r.

### ğŸ¤¡ Veri ArtÄ±rma (Data Augmentation)
AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi azaltmanÄ±n en basit yolu, eÄŸitim verilerinin boyutunu artÄ±rmaktÄ±r, daha fazla veri elde etmek Ã§ok maliyetli olduÄŸu iÃ§in her zaman mÃ¼mkÃ¼n deÄŸildir, ancak bazen verilerimize dayanarak verilerimizi artÄ±rabiliriz, Ã¶rneÄŸin:gg

* Resimler Ã¼zerinde dÃ¶nÃ¼ÅŸÃ¼m yapmak veri setimizi bÃ¼yÃ¼tebilir

### ğŸ›‘ Erken Durdurma
EÄŸitim setinin bir bÃ¶lÃ¼mÃ¼nÃ¼ doÄŸrulama seti olarak tuttuÄŸumuz bir tÃ¼r Ã§apraz doÄŸrulama stratejisidir. DoÄŸrulama setindeki performansÄ±n kÃ¶tÃ¼ye gittiÄŸini gÃ¶rdÃ¼ÄŸÃ¼mÃ¼zde, modelin eÄŸitimini derhal durdururuz. Bu _Erken Durma_ olarak bilinir.

## ğŸŒ YazÄ±nÄ±n AslÄ±
- [Burada ğŸ¾](https://dl.asmaamir.com/0-nnconcepts/6-regularization)

## ğŸ§ Daha Fazla Oku
* Uzun LafÄ±n KÄ±sasÄ± ğŸ˜…: [Overfitting and Regularization in Neural Networks](https://medium.com/@rameshkjes/overfitting-and-regularization-in-neural-networks-d3d996e33c3)